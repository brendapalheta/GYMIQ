# -*- coding: utf-8 -*-
"""Cópia de Árvore de decisão.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t4qPB4anxS4LOScLXOwb-BhwXOw0Nkuh
"""

# Importando as bibliotecas necessárias:
import pandas as pd
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.model_selection import train_test_split
from sklearn import metrics
import numpy as np
from sklearn.preprocessing import LabelEncoder, LabelBinarizer

# Carregando a base de dados:
df = pd.read_csv(r"c:\Users\Brenda Palheta\Desktop\gymiq_flask\gym_members_exercise_tracking.csv")
df.head()

# Informaçoes sobre a base:
df.info()

#Codificar os valores categoricos em numeros
labelencoder = LabelEncoder()
df = df.apply(labelencoder.fit_transform)
df.head()

#Entrada dos dados
X = df.drop(columns = ['Experience_Level'])
y = df['Experience_Level']      # Series 1D
# ou, ao usar train_test_split:
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# e ao ajustar:
# clf.fit(X_train, y_train)

# Dividindo os dados em treino e teste:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Verificando as formas dos dados:
X_train.shape,X_test.shape

y_train.shape,y_test.shape

# Instânciando o objeto classificador:
clf = DecisionTreeClassifier()

# Treinando o modelo de arvore de decisão:
clf = clf.fit(X_train,y_train)

# Verificando as features mais importantes para o modelo treinado:
clf.feature_importances_

for feature,importancia in zip(df.columns,clf.feature_importances_):
    print("{}:{}".format(feature, importancia))

resultado = clf.predict(X_test)

from sklearn import metrics
print(metrics.classification_report(y_test,resultado))

# Renderizando a árvore de forma gráfica:
import pydot
import graphviz

class_names = [str(c) for c in sorted(df['Experience_Level'].unique())]
dot_data = export_graphviz(clf, out_file=None, feature_names=X.columns, class_names=class_names, filled=True, rounded=True)

graph = graphviz.Source(dot_data)
graph.render(filename='arvore_decisao', format='png', cleanup=True)  # cria 'arvore_decisao.png'

# Renderizando a árvore de forma interativa:
from ipywidgets import interactive
from IPython.display import SVG,display
from graphviz import Source

# Carregando a base de dados:
df = pd.read_csv(r"c:\Users\Brenda Palheta\Desktop\gymiq_flask\gym_members_exercise_tracking.csv")
df.head()

#Codificar os valores categoricos em numeros
labelencoder = LabelEncoder()
df= df.apply(labelencoder.fit_transform)
df.head()
# feature matrix
X,y = df.drop('Experience_Level',axis=1),df['Experience_Level']



# feature labels
features_label = df.drop('Experience_Level',axis=1).columns

# class label
class_label = ['0','1']


def plot_tree(crit, split, depth, min_samples_split, min_samples_leaf=0.2):
    estimator = DecisionTreeClassifier(
           random_state = 0
          ,criterion = crit
          ,splitter = split
          ,max_depth = depth
          ,min_samples_split=min_samples_split
          ,min_samples_leaf=min_samples_leaf
    )
    estimator.fit(X, y)
    graph = Source(export_graphviz(estimator
      , out_file=None
      , feature_names=features_label
      , class_names=class_label
      , impurity=True
      , filled = True))
    display(SVG(graph.pipe(format='svg')))
    return estimator

inter=interactive(plot_tree
   , crit = ["gini", "entropy"]
   , split = ["best", "random"]
   , depth=[1,2,3,4,5,10,20,30]
   , min_samples_split=(1,5)
   , min_samples_leaf=(1,5))

import sys
if 'ipykernel' in sys.modules:
    # estamos em notebook -> mostrar interactive
    display(inter)
else:
    # ambiente terminal — pular UI
    pass

